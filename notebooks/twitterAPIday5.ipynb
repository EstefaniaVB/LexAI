{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from twython import Twython\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "#credentials = {}\n",
    "#credentials['CONSUMER_KEY'] = ''\n",
    "#credentials['CONSUMER_SECRET'] = ''\n",
    "#credentials['ACCESS_TOKEN'] = '-'\n",
    "#credentials['ACCESS_SECRET'] = ''\n",
    "\n",
    "# Save the credentials object to file\n",
    "#with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "#    json.dump(credentials, file)\n",
    "    \n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file) \n",
    "    \n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec5cc3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## look for key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61204b4",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = {'q': 'energy',\n",
    "        'result_type': 'recent',  # other options 'mixed','popular','recent'\n",
    "        'count': 10,   # max 100\n",
    "         # 'until':\"2019-02-01\",\n",
    "         'geocode': '51.51753,-0.11214,1000mi'\n",
    "        }\n",
    "\n",
    "dict_ = {'user': [],\n",
    "         'date': [],\n",
    "         'text': [],\n",
    "         'favorite_count': [],\n",
    "         'retweet_count': [],\n",
    "         'user_loc': [],\n",
    "         'followers_count': [],\n",
    "         'lang': [],\n",
    "         'user_desc': [],\n",
    "         'hashtags': [],\n",
    "         'user_verified': [],\n",
    "         'geo': [],\n",
    "         'coordinates':[],\n",
    "         'place':[],\n",
    "         #'user_loc_country':[]\n",
    "         \n",
    "        }\n",
    "\n",
    "\n",
    "for status in python_tweets.search(**query)['statuses']:\n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['text'])\n",
    "    dict_['favorite_count'].append(status['favorite_count'])\n",
    "    dict_['user_loc'].append( status['user']['location'])\n",
    "    dict_['followers_count'].append(status['user']['followers_count'])\n",
    "    dict_['lang'].append(status['lang'])\n",
    "    dict_['user_desc'].append(status['user']['description'])\n",
    "    dict_['user_verified'].append(status['user']['verified'])\n",
    "    dict_['hashtags'].append(status['entities']['hashtags'])\n",
    "    dict_['retweet_count'].append(status['retweet_count'])\n",
    "    dict_['geo'].append(status['geo'])\n",
    "    dict_['coordinates'].append(status['coordinates'])\n",
    "    dict_['place'].append(status['place'])\n",
    "    #dict_['user_loc_country'].append(status['user']['derived']['locations']['country'])\n",
    "    \n",
    "df = pd.DataFrame(dict_)\n",
    "#dict_['text'][0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9f02e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b5fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a6b5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities = pd.read_csv('list_cities.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397dfdb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Translate queries and Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0f571",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "from google.cloud import translate\n",
    "\n",
    "def gtrans(text,dest='en'):\n",
    "    \n",
    "    '''this function represents the google translate API. use wisely!\n",
    "    its expensive (20$/1mio characters, makes only 5000 tweets)'''\n",
    "    \n",
    "    \n",
    "    project_id = 'lewagon-bootcamp-timwolfram' #environ.get(\"PROJECT_ID\", \"\")\n",
    "\n",
    "    parent = f\"projects/{project_id}\"\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "\n",
    "    sample_text = text\n",
    "    target_language_code = dest\n",
    "\n",
    "    response = client.translate_text(\n",
    "        contents=[sample_text],\n",
    "        target_language_code=target_language_code,\n",
    "        parent=parent,\n",
    "    )\n",
    "\n",
    "    for translation in response.translations:\n",
    "        output_trans = translation.translated_text\n",
    "        \n",
    "    return output_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c99823",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gtrans('Hallo Welt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e3063",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_ = {'user': [],\n",
    "             'date': [],\n",
    "             'text': [],\n",
    "             'text_en': [],\n",
    "             'favorite_count': [],\n",
    "             'retweet_count': [],\n",
    "             'user_loc': [],\n",
    "             'followers_count': [],\n",
    "             'lang': [],\n",
    "             'user_desc': [],\n",
    "             'user_desc_en': [],\n",
    "             'hashtags': [],\n",
    "             'user_verified': [],\n",
    "\n",
    "             #'geo': [],\n",
    "             #'coordinates':[],\n",
    "             #'place':[]\n",
    "\n",
    "             #'user_loc_country':[]\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "query_word = 'energy'\n",
    "\n",
    "lang_list = ['en','de','fr','el','it','es',\n",
    "                'pl', 'ro', 'nl', 'hu','pt',\n",
    "                'sv',  'cs', 'bg', 'sk', 'da',\n",
    "                'fi', 'hr', 'lt'\n",
    "            ]\n",
    "\n",
    "count_tweets = 1\n",
    "result_type = 'mixed'\n",
    "\n",
    "for lang in lang_list:\n",
    "    \n",
    "    query_word = gtrans(query_word, dest=lang)\n",
    "    if lang == 'en':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '51.51753,-0.11214,1000mi'\n",
    "            }\n",
    "        \n",
    "    elif lang == 'fr':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '47.22283,2.07099,1000mi'\n",
    "            }\n",
    "    elif lang == 'es':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': ' 40.42955,-3.67930,1000mi'\n",
    "            }\n",
    "        \n",
    "    elif lang == 'pt':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '39.82059,-7.49342,1000mi'\n",
    "            }\n",
    "        \n",
    "    else:\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "             # 'until':\"2019-02-01\",\n",
    "             #'geocode': '50.0598058,14.3255426,1000km'\n",
    "            }\n",
    "\n",
    "   \n",
    "    for status in python_tweets.search(**query)['statuses']:\n",
    "        \n",
    "        dict_['user'].append(status['user']['screen_name'])\n",
    "        dict_['date'].append(status['created_at'])\n",
    "        dict_['text'].append(status['text'])\n",
    "        dict_['text_en'].append(gtrans(str(status['text']), dest='en'))#src=str(status['lang'])\n",
    "        dict_['favorite_count'].append(status['favorite_count'])\n",
    "        dict_['user_loc'].append( status['user']['location'])\n",
    "        dict_['followers_count'].append(status['user']['followers_count'])\n",
    "        dict_['lang'].append(status['lang'])\n",
    "        dict_['user_desc'].append(status['user']['description'])\n",
    "        try:\n",
    "            dict_['user_desc_en'].append(gtrans(str(status['user']['description']), dest='en'))\n",
    "        except:\n",
    "            dict_['user_desc_en'].append('none')\n",
    "        dict_['user_verified'].append(status['user']['verified'])\n",
    "        dict_['hashtags'].append(status['entities']['hashtags'])\n",
    "        dict_['retweet_count'].append(status['retweet_count'])\n",
    "\n",
    "\n",
    "        #dict_['geo'].append(status['geo'])\n",
    "        #dict_['coordinates'].append(status['coordinates'])\n",
    "        #dict_['place'].append(status['place'])\n",
    "        #dict_['user_loc_country'].append(status['user']['derived']['locations']['country'])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dict_)\n",
    "#dict_['text']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306abcd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities = pd.read_csv('list_cities2.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f055f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6113f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### filter for european countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23102c91",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046b884",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('brown')\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04798b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = df['text_en'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff336fe9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#text = text.lower()\n",
    "\n",
    "##remove punctiation\n",
    "\n",
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "    \n",
    "##remove stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(text) \n",
    "  \n",
    "text = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "#text = ' '.join(text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028d2c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85cbe2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki = TextBlob(text)\n",
    "#wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6374e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(wiki.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6624",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testimonial = TextBlob(text)\n",
    "print(testimonial.sentiment)\n",
    "print(testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc2bd8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## all functions for .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a90772c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import translate\n",
    "from twython import Twython\n",
    "\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "#credentials = {}\n",
    "#credentials['CONSUMER_KEY'] = ''\n",
    "#credentials['CONSUMER_SECRET'] = ''\n",
    "#credentials['ACCESS_TOKEN'] = '-'\n",
    "#credentials['ACCESS_SECRET'] = ''\n",
    "\n",
    "#Save the credentials object to file\n",
    "#with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "#    json.dump(credentials, file)\n",
    "    \n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file) \n",
    "    \n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])    \n",
    "\n",
    "\n",
    "def get_places():\n",
    "    \n",
    "    '''creates a list of places and countries in europe, for locality-filtering the output tweets'''\n",
    "    cities = pd.read_csv('list_cities3.csv',delimiter=';')\n",
    "    \n",
    "    list_cities = list(cities['city'])\n",
    "    list_cities = [element.lower() for element in list_cities]\n",
    "    list_countries = list(set(cities['county']))\n",
    "    list_countries = [element.lower() for element in list_countries]\n",
    "    list_eur = list_cities + list_countries\n",
    "    return list_eur\n",
    "\n",
    "\n",
    "def gtrans(text,dest='en'):\n",
    "    \n",
    "    '''this function represents the google translate API. use wisely!\n",
    "    its expensive (20$/1mio characters, makes only 5000 tweets)'''\n",
    "    \n",
    "    \n",
    "    project_id = 'lewagon-bootcamp-timwolfram' #environ.get(\"PROJECT_ID\", \"\")\n",
    "\n",
    "    parent = f\"projects/{project_id}\"\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "\n",
    "    sample_text = text\n",
    "    target_language_code = dest\n",
    "\n",
    "    response = client.translate_text(\n",
    "        contents=[sample_text],\n",
    "        target_language_code=target_language_code,\n",
    "        parent=parent,\n",
    "    )\n",
    "\n",
    "    for translation in response.translations:\n",
    "        output_trans = translation.translated_text\n",
    "        \n",
    "    return output_trans\n",
    "\n",
    "\n",
    "def local_filter(tweets, list_eur=get_places(), no_loc=True):\n",
    "    \n",
    "    '''filters the output of the get_tweets function to only get european posts'''\n",
    "    \n",
    "    if no_loc == True:\n",
    "        list_eur.append('')\n",
    "        \n",
    "    for tweet in tweets:\n",
    "        if not tweet['user_loc'].split(',')[0] in list_eur:\n",
    "            tweets.remove(tweet)\n",
    "        \n",
    "        \n",
    "    return tweets\n",
    "\n",
    "\n",
    "def remove_duplicates(tweets):\n",
    "    li = []\n",
    "    for tweet in tweets:\n",
    "        if not tweet in li:\n",
    "            li.append(tweet)\n",
    "\n",
    "    return li\n",
    "\n",
    "\n",
    "def get_tweets(query,count,result_type='mixed'):   #count: max 10 because its looking for all 19 languages at once\n",
    "\n",
    "    '''this function uses the twitter search endpoint with max 190 requests/15 min\n",
    "    the output is a list of dictionaries with one dict per tweet.\n",
    "    keys are the features of the tweets'''\n",
    "    \n",
    "    ''' it uses the google-translate API wich kosts 20$ per ~5000 tweets '''\n",
    "\n",
    "    query_word = query\n",
    "    count_tweets = count\n",
    "    \n",
    "    lang_list = ['en','de','fr','el','it','es',\n",
    "                    'pl', 'ro', 'nl', 'hu','pt',\n",
    "                    'sv',  'cs', 'bg', 'sk', 'da',\n",
    "                    'fi', 'hr', 'lt'\n",
    "                ]\n",
    "\n",
    "    #dict_ = {}\n",
    "    \n",
    "    result_type = result_type # other options 'mixed','popular','recent'\n",
    "\n",
    "    list_tweets = []\n",
    "\n",
    "    for lang in lang_list:\n",
    "\n",
    "        query_word = gtrans(query_word, dest=lang)\n",
    "        if lang == 'en':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '51.51753,-0.11214,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        elif lang == 'fr':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '47.22283,2.07099,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "            \n",
    "        elif lang == 'es':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '40.42955,-3.67930,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        elif lang == 'pt':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '39.82059,-7.49342,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  # \n",
    "                'count': count_tweets,   # max 100\n",
    "                #'geocode': '50.0598058,14.3255426,1000km'\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "\n",
    "        for status in python_tweets.search(**query)['statuses']:\n",
    "            dict_ = {}\n",
    "            dict_['id'] = status['id']\n",
    "            dict_['user'] = status['user']['screen_name']\n",
    "            dict_['date'] = status['created_at']\n",
    "            dict_['text'] = status['full_text']\n",
    "            dict_['text_en'] = gtrans(str(status['full_text']), dest='en')\n",
    "            dict_['favorite_count'] = status['favorite_count']\n",
    "            dict_['user_loc'] =  status['user']['location']\n",
    "            dict_['followers_count'] = status['user']['followers_count']\n",
    "            dict_['lang'] = status['lang']\n",
    "            dict_['user_desc'] = status['user']['description']\n",
    "            try:\n",
    "                dict_['user_desc_en'] = gtrans(str(status['user']['description']), dest='en')\n",
    "            except:\n",
    "                dict_['user_desc_en'] = 'none'\n",
    "            dict_['user_verified'] = status['user']['verified']\n",
    "            dict_['hashtags'] = status['entities']['hashtags']\n",
    "            dict_['retweet_count'] = status['retweet_count']\n",
    "\n",
    "            list_tweets.append(dict_) \n",
    "    \n",
    "    return list_tweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20344c17",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets = get_tweets('energy',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e039c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1847a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tweets_local = local_filter(tweets)\n",
    "len(tweets_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61708316",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(tweets_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727a1b1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a3b232",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec00630f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When they opened up the energy market to competition, they promised the French that it would lower prices. This is not true. When they imposed the #Linky counter, they told the French that it would cost them nothing. This is not true. # les4V https://t.co/Jw5Adc1hom'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_en'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eace1b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de63269",
   "metadata": {},
   "source": [
    "## geographical mapping of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7297c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-971dee01e7204e64b1d599386047400f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-971dee01e7204e64b1d599386047400f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-971dee01e7204e64b1d599386047400f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/world-110m.json\", \"format\": {\"feature\": \"countries\", \"type\": \"topojson\"}}, \"mark\": {\"type\": \"geoshape\", \"fill\": \"#666666\", \"stroke\": \"white\"}, \"height\": 300, \"projection\": {\"center\": [20, 50], \"clipExtent\": [[0, 0], [400, 300]], \"scale\": 350, \"type\": \"mercator\"}, \"title\": \"Europe (Mercator)\", \"width\": 400, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "countries = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "\n",
    "alt.Chart(countries).mark_geoshape(\n",
    "    fill='#666666',\n",
    "    stroke='white'\n",
    ").project(\n",
    "    type= 'mercator',\n",
    "    scale= 350,                          # Magnify\n",
    "    center= [20,50],                     # [lon, lat]\n",
    "    clipExtent= [[0, 0], [400, 300]],    # [[left, top], [right, bottom]]\n",
    ").properties(\n",
    "    title='Europe (Mercator)',\n",
    "    width=400, height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c19492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
