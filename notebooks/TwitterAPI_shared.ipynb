{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from twython import Twython\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "#credentials = {}\n",
    "#credentials['CONSUMER_KEY'] = ''\n",
    "#credentials['CONSUMER_SECRET'] = ''\n",
    "#credentials['ACCESS_TOKEN'] = '-'\n",
    "#credentials['ACCESS_SECRET'] = ''\n",
    "\n",
    "# Save the credentials object to file\n",
    "#with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "#    json.dump(credentials, file)\n",
    "    \n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file) \n",
    "    \n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec5cc3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## look for key word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61204b4",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = {'q': 'energy',\n",
    "        'result_type': 'recent',  # other options 'mixed','popular','recent'\n",
    "        'count': 10,   # max 100\n",
    "         # 'until':\"2019-02-01\",\n",
    "         'geocode': '51.51753,-0.11214,1000mi'\n",
    "        }\n",
    "\n",
    "dict_ = {'user': [],\n",
    "         'date': [],\n",
    "         'text': [],\n",
    "         'favorite_count': [],\n",
    "         'retweet_count': [],\n",
    "         'user_loc': [],\n",
    "         'followers_count': [],\n",
    "         'lang': [],\n",
    "         'user_desc': [],\n",
    "         'hashtags': [],\n",
    "         'user_verified': [],\n",
    "         'geo': [],\n",
    "         'coordinates':[],\n",
    "         'place':[],\n",
    "         #'user_loc_country':[]\n",
    "         \n",
    "        }\n",
    "\n",
    "\n",
    "for status in python_tweets.search(**query)['statuses']:\n",
    "    dict_['user'].append(status['user']['screen_name'])\n",
    "    dict_['date'].append(status['created_at'])\n",
    "    dict_['text'].append(status['text'])\n",
    "    dict_['favorite_count'].append(status['favorite_count'])\n",
    "    dict_['user_loc'].append( status['user']['location'])\n",
    "    dict_['followers_count'].append(status['user']['followers_count'])\n",
    "    dict_['lang'].append(status['lang'])\n",
    "    dict_['user_desc'].append(status['user']['description'])\n",
    "    dict_['user_verified'].append(status['user']['verified'])\n",
    "    dict_['hashtags'].append(status['entities']['hashtags'])\n",
    "    dict_['retweet_count'].append(status['retweet_count'])\n",
    "    dict_['geo'].append(status['geo'])\n",
    "    dict_['coordinates'].append(status['coordinates'])\n",
    "    dict_['place'].append(status['place'])\n",
    "    #dict_['user_loc_country'].append(status['user']['derived']['locations']['country'])\n",
    "    \n",
    "df = pd.DataFrame(dict_)\n",
    "#dict_['text'][0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9f02e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b5fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a6b5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities = pd.read_csv('list_cities.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397dfdb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Translate queries and Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07384328",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "from google.cloud import translate\n",
    "\n",
    "def gtrans(text,dest='en'):\n",
    "    \n",
    "    '''this function represents the google translate API. use wisely!\n",
    "    its expensive (20$/1mio characters, makes only 5000 tweets)'''\n",
    "    \n",
    "    \n",
    "    project_id = 'lewagon-bootcamp-timwolfram' #environ.get(\"PROJECT_ID\", \"\")\n",
    "\n",
    "    parent = f\"projects/{project_id}\"\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "\n",
    "    sample_text = text\n",
    "    target_language_code = dest\n",
    "\n",
    "    response = client.translate_text(\n",
    "        contents=[sample_text],\n",
    "        target_language_code=target_language_code,\n",
    "        parent=parent,\n",
    "    )\n",
    "\n",
    "    for translation in response.translations:\n",
    "        output_trans = translation.translated_text\n",
    "        \n",
    "    return output_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c99823",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gtrans('Hallo Welt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e3063",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_ = {'user': [],\n",
    "             'date': [],\n",
    "             'text': [],\n",
    "             'text_en': [],\n",
    "             'favorite_count': [],\n",
    "             'retweet_count': [],\n",
    "             'user_loc': [],\n",
    "             'followers_count': [],\n",
    "             'lang': [],\n",
    "             'user_desc': [],\n",
    "             'user_desc_en': [],\n",
    "             'hashtags': [],\n",
    "             'user_verified': [],\n",
    "\n",
    "             #'geo': [],\n",
    "             #'coordinates':[],\n",
    "             #'place':[]\n",
    "\n",
    "             #'user_loc_country':[]\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "query_word = 'energy'\n",
    "\n",
    "lang_list = ['en','de','fr','el','it','es',\n",
    "                'pl', 'ro', 'nl', 'hu','pt',\n",
    "                'sv',  'cs', 'bg', 'sk', 'da',\n",
    "                'fi', 'hr', 'lt'\n",
    "            ]\n",
    "\n",
    "count_tweets = 1\n",
    "result_type = 'mixed'\n",
    "\n",
    "for lang in lang_list:\n",
    "    \n",
    "    query_word = gtrans(query_word, dest=lang)\n",
    "    if lang == 'en':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '51.51753,-0.11214,1000mi'\n",
    "            }\n",
    "        \n",
    "    elif lang == 'fr':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '47.22283,2.07099,1000mi'\n",
    "            }\n",
    "    elif lang == 'es':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': ' 40.42955,-3.67930,1000mi'\n",
    "            }\n",
    "        \n",
    "    elif lang == 'pt':\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "            'geocode': '39.82059,-7.49342,1000mi'\n",
    "            }\n",
    "        \n",
    "    else:\n",
    "        query = {'q': query_word,\n",
    "            'result_type': result_type,  # other options 'mixed','popular','recent'\n",
    "            'count': count_tweets,   # max 100\n",
    "             # 'until':\"2019-02-01\",\n",
    "             #'geocode': '50.0598058,14.3255426,1000km'\n",
    "            }\n",
    "\n",
    "   \n",
    "    for status in python_tweets.search(**query)['statuses']:\n",
    "        \n",
    "        dict_['user'].append(status['user']['screen_name'])\n",
    "        dict_['date'].append(status['created_at'])\n",
    "        dict_['text'].append(status['text'])\n",
    "        dict_['text_en'].append(gtrans(str(status['text']), dest='en'))#src=str(status['lang'])\n",
    "        dict_['favorite_count'].append(status['favorite_count'])\n",
    "        dict_['user_loc'].append( status['user']['location'])\n",
    "        dict_['followers_count'].append(status['user']['followers_count'])\n",
    "        dict_['lang'].append(status['lang'])\n",
    "        dict_['user_desc'].append(status['user']['description'])\n",
    "        try:\n",
    "            dict_['user_desc_en'].append(gtrans(str(status['user']['description']), dest='en'))\n",
    "        except:\n",
    "            dict_['user_desc_en'].append('none')\n",
    "        dict_['user_verified'].append(status['user']['verified'])\n",
    "        dict_['hashtags'].append(status['entities']['hashtags'])\n",
    "        dict_['retweet_count'].append(status['retweet_count'])\n",
    "\n",
    "\n",
    "        #dict_['geo'].append(status['geo'])\n",
    "        #dict_['coordinates'].append(status['coordinates'])\n",
    "        #dict_['place'].append(status['place'])\n",
    "        #dict_['user_loc_country'].append(status['user']['derived']['locations']['country'])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dict_)\n",
    "#dict_['text']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306abcd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities = pd.read_csv('list_cities2.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba16a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb683308",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### filter for european countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61f712",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539f720",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('brown')\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9379d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = df['text_en'][1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b38b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#text = text.lower()\n",
    "\n",
    "##remove punctiation\n",
    "\n",
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "    \n",
    "##remove stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(text) \n",
    "  \n",
    "text = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "#text = ' '.join(text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6ddc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f495b57",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wiki = TextBlob(text)\n",
    "#wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e368f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(wiki.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79931467",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testimonial = TextBlob(text)\n",
    "print(testimonial.sentiment)\n",
    "print(testimonial.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214cf9e",
   "metadata": {},
   "source": [
    "## all functions for .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6651f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "import json\n",
    "import pandas as pd\n",
    "from google.cloud import translate\n",
    "from twython import Twython\n",
    "\n",
    "\n",
    "# Enter your keys/secrets as strings in the following fields\n",
    "#credentials = {}\n",
    "#credentials['CONSUMER_KEY'] = ''\n",
    "#credentials['CONSUMER_SECRET'] = ''\n",
    "#credentials['ACCESS_TOKEN'] = '-'\n",
    "#credentials['ACCESS_SECRET'] = ''\n",
    "\n",
    "#Save the credentials object to file\n",
    "#with open(\"twitter_credentials.json\", \"w\") as file:\n",
    "#    json.dump(credentials, file)\n",
    "    \n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file) \n",
    "    \n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])    \n",
    "\n",
    "\n",
    "def get_places():\n",
    "    \n",
    "    '''creates a list of places and countries in europe, for locality-filtering the output tweets'''\n",
    "    cities = pd.read_csv('list_cities3.csv',delimiter=';')\n",
    "    \n",
    "    list_cities = list(cities['city'])\n",
    "    list_cities = [element.lower() for element in list_cities]\n",
    "    list_countries = list(set(cities['county']))\n",
    "    list_countries = [element.lower() for element in list_countries]\n",
    "    list_eur = list_cities + list_countries\n",
    "    return list_eur\n",
    "\n",
    "\n",
    "def gtrans(text,dest='en'):\n",
    "    \n",
    "    '''this function represents the google translate API. use wisely!\n",
    "    its expensive (20$/1mio characters, makes only 5000 tweets)'''\n",
    "    \n",
    "    \n",
    "    project_id = 'lewagon-bootcamp-timwolfram' #environ.get(\"PROJECT_ID\", \"\")\n",
    "\n",
    "    parent = f\"projects/{project_id}\"\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "\n",
    "    sample_text = text\n",
    "    target_language_code = dest\n",
    "\n",
    "    response = client.translate_text(\n",
    "        contents=[sample_text],\n",
    "        target_language_code=target_language_code,\n",
    "        parent=parent,\n",
    "    )\n",
    "\n",
    "    for translation in response.translations:\n",
    "        output_trans = translation.translated_text\n",
    "        \n",
    "    return output_trans\n",
    "\n",
    "\n",
    "def local_filter(tweets, list_eur=get_places(), no_loc=True):\n",
    "    \n",
    "    '''filters the output of the get_tweets function to only get european posts'''\n",
    "    \n",
    "    if no_loc == True:\n",
    "        list_eur.append('')\n",
    "        \n",
    "    for tweet in tweets:\n",
    "        if not tweet['user_loc'].split(',')[0] in list_eur:\n",
    "            tweets.remove(tweet)\n",
    "        \n",
    "        \n",
    "    return tweets\n",
    "\n",
    "\n",
    "def remove_duplicates(tweets):\n",
    "    li = []\n",
    "    for tweet in tweets:\n",
    "        if not tweet in li:\n",
    "            li.append(tweet)\n",
    "\n",
    "    return li\n",
    "\n",
    "\n",
    "def get_tweets(query,count,result_type='mixed'):   #count: max 10 because its looking for all 19 languages at once\n",
    "\n",
    "    '''this function uses the twitter search endpoint with max 190 requests/15 min\n",
    "    the output is a list of dictionaries with one dict per tweet.\n",
    "    keys are the features of the tweets'''\n",
    "    \n",
    "    ''' it uses the google-translate API wich kosts 20$ per ~5000 tweets '''\n",
    "\n",
    "    query_word = query\n",
    "    count_tweets = count\n",
    "    \n",
    "    lang_list = ['en','de','fr','el','it','es',\n",
    "                    'pl', 'ro', 'nl', 'hu','pt',\n",
    "                    'sv',  'cs', 'bg', 'sk', 'da',\n",
    "                    'fi', 'hr', 'lt'\n",
    "                ]\n",
    "\n",
    "    #dict_ = {}\n",
    "    \n",
    "    result_type = result_type # other options 'mixed','popular','recent'\n",
    "\n",
    "    list_tweets = []\n",
    "\n",
    "    for lang in lang_list:\n",
    "\n",
    "        query_word = gtrans(query_word, dest=lang)\n",
    "        if lang == 'en':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '51.51753,-0.11214,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        elif lang == 'fr':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '47.22283,2.07099,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "            \n",
    "        elif lang == 'es':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '40.42955,-3.67930,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        elif lang == 'pt':\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  \n",
    "                'count': count_tweets,   # max 100\n",
    "                'geocode': '39.82059,-7.49342,1000mi',\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            query = {'q': query_word,\n",
    "                'result_type': result_type,  # \n",
    "                'count': count_tweets,   # max 100\n",
    "                #'geocode': '50.0598058,14.3255426,1000km'\n",
    "                'tweet_mode': 'extended'\n",
    "                }\n",
    "\n",
    "\n",
    "        for status in python_tweets.search(**query)['statuses']:\n",
    "            dict_ = {}\n",
    "            dict_['id'] = status['id']\n",
    "            dict_['user'] = status['user']['screen_name']\n",
    "            dict_['date'] = status['created_at']\n",
    "            dict_['text'] = status['full_text']\n",
    "            dict_['text_en'] = gtrans(str(status['full_text']), dest='en')\n",
    "            dict_['favorite_count'] = status['favorite_count']\n",
    "            dict_['user_loc'] =  status['user']['location']\n",
    "            dict_['followers_count'] = status['user']['followers_count']\n",
    "            dict_['lang'] = status['lang']\n",
    "            dict_['user_desc'] = status['user']['description']\n",
    "            try:\n",
    "                dict_['user_desc_en'] = gtrans(str(status['user']['description']), dest='en')\n",
    "            except:\n",
    "                dict_['user_desc_en'] = 'none'\n",
    "            dict_['user_verified'] = status['user']['verified']\n",
    "            dict_['hashtags'] = status['entities']['hashtags']\n",
    "            dict_['retweet_count'] = status['retweet_count']\n",
    "\n",
    "            list_tweets.append(dict_) \n",
    "    \n",
    "    return list_tweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0405562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets('energy',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01065735",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0cf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_local = local_filter(tweets)\n",
    "len(tweets_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tweets_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e16caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4dba106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6732485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When they opened up the energy market to competition, they promised the French that it would lower prices. This is not true. When they imposed the #Linky counter, they told the French that it would cost them nothing. This is not true. # les4V https://t.co/Jw5Adc1hom'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_en'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a477058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
